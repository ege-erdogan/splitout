{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2cyrz6-5BMk"
      },
      "source": [
        "# SplitOut: Out-of-the-Box Training-Hijacking Detection in Split Learning via Outlier Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "251kwIF_c6Br",
        "outputId": "073854d6-6e03-4fcb-818d-28203af7cf04"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms, datasets\n",
        "from torchvision.utils import save_image\n",
        "from scipy.stats import sem\n",
        "import math\n",
        "import itertools\n",
        "import statistics\n",
        "import pickle\n",
        "# import architectures_torch as architectures\n",
        "\n",
        "from models import *\n",
        "from util import *\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "from torchvision.models import resnet18\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import time\n",
        "import io\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print('Running on', device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J11zDtSLdMT6",
        "outputId": "49ae1248-497c-4e31-b36b-3cd68b5f073f"
      },
      "outputs": [],
      "source": [
        "trainloader, testloader = load_dataset('cifar')\n",
        "print(len(trainloader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08jdqoD99k-t",
        "outputId": "b1bfc808-acde-4b19-c56f-efc1707d8e48"
      },
      "outputs": [],
      "source": [
        "TOTAL_BATCHES = len(trainloader)\n",
        "# TOTAL_BATCHES = 3750\n",
        "TOTAL_BATCHES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5NyS05FBmLE",
        "outputId": "77922e69-16de-4a32-eadc-43d8d7aabb81"
      },
      "outputs": [],
      "source": [
        "# Colab Drive Connection\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VMYeiibQhKqS"
      },
      "outputs": [],
      "source": [
        "# initialization of pickle loader\n",
        "class CPU_Unpickler(pickle.Unpickler):\n",
        "    def find_class(self, module, name):\n",
        "        if module == 'torch.storage' and name == '_load_from_bytes':\n",
        "            return lambda b: torch.load(io.BytesIO(b), map_location='cpu')\n",
        "        else:\n",
        "          return super().find_class(module, name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B993RS14_o_K"
      },
      "source": [
        "### 1) Loading FSHA and honest gradients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xMJvMnyYu6l1"
      },
      "outputs": [],
      "source": [
        "def load_gradients(file_name, number_of_files, print_info=True):\n",
        "    grads_original = []\n",
        "\n",
        "    for pickled_file in range(number_of_files):\n",
        "        file = open(file_name + str(pickled_file), 'rb')\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            gradients_list = pickle.load(file)\n",
        "        else:\n",
        "            gradients_list = CPU_Unpickler(file).load()\n",
        "\n",
        "        grads_original.append(gradients_list)\n",
        "        file.close()\n",
        "\n",
        "    if print_info:\n",
        "        print(\"Data structure of a gradient: \",type(grads_original))\n",
        "        print(\"Gradients brief info: {} epochs, {} gradients in an epoch, single gradient length in size  {}\".format(\n",
        "            len(grads_original), len(grads_original[0]), len(grads_original[0][0])\n",
        "        ))\n",
        "        print()\n",
        "\n",
        "    return grads_original"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ft32X13tzPFN",
        "outputId": "00004500-7ade-4634-83cb-aa864b3d4d8e"
      },
      "outputs": [],
      "source": [
        "drive_path = '/content/drive/MyDrive/grads'\n",
        "# load all gradients from honest server\n",
        "honest_grads_original =  load_gradients(drive_path+'/HONEST_cifar10/honest_cifar_grads_', 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "YqZ9w9aaWJIP",
        "outputId": "1436e18c-0373-45d3-b06f-77e93f20d0cd"
      },
      "outputs": [],
      "source": [
        "# load all gradients from FSHA server\n",
        "fsha_grads_original =  load_gradients(drive_path+'/SSPY_cifar10/FSHA_newAtt_cifar10_regulars_', 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vM8kn8xyu6l1"
      },
      "source": [
        "### 2) Client NN training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApZuv3N0K_Jl"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()\n",
        "REPS = 100 # number of reps to average scores from\n",
        "model_str = 'resnet'\n",
        "optimizer = 'adam'\n",
        "dataset = 'cifar'\n",
        "del trainloader, testloader\n",
        "trainloader, testloader = load_dataset(dataset)\n",
        "print(dataset, model_str)\n",
        "\n",
        "# other params\n",
        "NUM_CLASSES = 100 if dataset == 'cifar100' else 10\n",
        "EPOCHS = 1 # number of epochs to run simulation for\n",
        "SETUPS = [('honest')]\n",
        "\n",
        "client_collected_grads = []\n",
        "\n",
        "for rep in tqdm(range(REPS)):\n",
        "    client_temp_collected_grads = []\n",
        "    start_time_nn_train = time.time()\n",
        "\n",
        "    for adv_type in SETUPS:\n",
        "        model = get_models(model_str,  dataset, device)\n",
        "\n",
        "        client_opt, server_opt = get_optims(optimizer, model, model)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        for epoch in range(1):\n",
        "            for index, item in enumerate(tqdm(trainloader, leave=False)):\n",
        "                images, labels = item[0].to(device), item[1].to(device)\n",
        "                client_opt.zero_grad()\n",
        "                server_opt.zero_grad()\n",
        "\n",
        "                pred = model(images)\n",
        "                loss = criterion(pred, labels)\n",
        "\n",
        "                # loss backward, collect client grad\n",
        "                loss.backward()\n",
        "                client_grad = list(model.parameters())[0].grad.detach().clone().flatten()\n",
        "                # # client_temp_collected_grads.append(client_grad) # collect train grads\n",
        "\n",
        "    end_time_nn_train = time.time()\n",
        "    print(f\"Setup {rep} training is completed. Elasped time: {round(end_time_nn_train-start_time_nn_train,3)}\")\n",
        "    # print(\"len collected train grads: \", len(cli_10_collected_grads))\n",
        "    client_collected_grads.append(client_temp_collected_grads)\n",
        "\n",
        "\n",
        "print(\"Number of epochs: \", len(client_collected_grads))\n",
        "\n",
        "torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h4I2ghM4q6RA"
      },
      "outputs": [],
      "source": [
        "for i in range(len(client_collected_grads)):\n",
        "  print(len(client_collected_grads[i]), \"==>\", len(client_collected_grads[i][0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFx6sDdtACMy"
      },
      "source": [
        "### 3) Converting Tensor gradients to NumPy Array\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "R9sXHbQru6l2"
      },
      "outputs": [],
      "source": [
        "def grad_tensor_to_numpy_converter(original_gradients, print_info=True):\n",
        "    new_gradients_nparray = []\n",
        "\n",
        "    for new_epoch in range(len(original_gradients)):\n",
        "\n",
        "        new_grads_one_epoch = []\n",
        "        for new_gradient in range(len(original_gradients[new_epoch])):\n",
        "            new_grads_one_epoch.append(original_gradients[new_epoch][new_gradient].detach().cpu().numpy())\n",
        "        new_gradients_nparray.append(new_grads_one_epoch)\n",
        "\n",
        "    if print_info == True:\n",
        "        print(\"Initial D.S. of one gradient in an epoch: \",type(original_gradients[0][0]))\n",
        "        print(\"After conversion, D.S. of one gradient in an epoch: \",type(new_gradients_nparray[0][0]))\n",
        "        print(\"Gradients brief info: {} epochs, {} gradients, single gradient length in size  {}\".format(\n",
        "            len(new_gradients_nparray), len(new_gradients_nparray[0]), len(new_gradients_nparray[0][0])\n",
        "        ))\n",
        "        print()\n",
        "\n",
        "    return new_gradients_nparray\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fpl8vddpwWWE",
        "outputId": "f7f7f317-1cfc-464a-c81e-4143afc994e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial D.S. of one gradient in an epoch:  <class 'torch.Tensor'>\n",
            "After conversion, D.S. of one gradient in an epoch:  <class 'numpy.ndarray'>\n",
            "Gradients brief info: 100 epochs, 782 gradients, single gradient length in size  1728\n",
            "\n",
            "Initial D.S. of one gradient in an epoch:  <class 'torch.Tensor'>\n",
            "After conversion, D.S. of one gradient in an epoch:  <class 'numpy.ndarray'>\n",
            "Gradients brief info: 100 epochs, 809 gradients, single gradient length in size  1728\n",
            "\n"
          ]
        }
      ],
      "source": [
        "honest_grads_nparray = grad_tensor_to_numpy_converter(honest_grads_original)\n",
        "fsha_grads_nparray = grad_tensor_to_numpy_converter(fsha_grads_original)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuMhEii3_JT6"
      },
      "source": [
        "### 3.1. (optional) Reduce number of batches\n",
        "If your number of iterations is more than the required number of batches, you can\n",
        "reduce the number of batches:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "cCy4Ami0C6f5"
      },
      "outputs": [],
      "source": [
        "def grads_list_epoch_reducer(grads_nparray, TOTAL_BATCHES):\n",
        "  grads_nparray_REDUCED = []\n",
        "\n",
        "  CUT_GRAD = TOTAL_BATCHES\n",
        "  print(f\"Cut gradients at: {CUT_GRAD}\")\n",
        "\n",
        "  for epoch_in_arr in range(len(grads_nparray)):\n",
        "\n",
        "    grads_one_epoch = []\n",
        "\n",
        "    if len(grads_nparray[epoch_in_arr]) < CUT_GRAD:\n",
        "      grads_one_epoch = grads_nparray[epoch_in_arr]\n",
        "    else:\n",
        "      for grad in range(CUT_GRAD):\n",
        "          grads_one_epoch.append(grads_nparray[epoch_in_arr][grad])\n",
        "\n",
        "    grads_nparray_REDUCED.append(grads_one_epoch)\n",
        "\n",
        "  print(\"Number of honest epochs after reduced data rate: {}\".format(len(grads_nparray_REDUCED)))\n",
        "\n",
        "  # check number of gradients and rates for first 10 epoch\n",
        "  print(\"First 10 epoch number of gradients and data rates:\")\n",
        "  for i in range(10):\n",
        "    print(\"({}, {}%) \".format(\n",
        "      len(grads_nparray_REDUCED[i]),\n",
        "      round((len(grads_nparray_REDUCED[i])/len(grads_nparray_REDUCED[i])),2)*100),\n",
        "      end= \" \")\n",
        "  return grads_nparray_REDUCED"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubj95802JcGa",
        "outputId": "ce40eb19-35fd-47d5-d1bd-cb29e601fdcc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cut gradients at: 782\n",
            "Number of honest epochs after reduced data rate: 100\n",
            "First 10 epoch number of gradients and data rates:\n",
            "(782, 100.0%)  (782, 100.0%)  (782, 100.0%)  (782, 100.0%)  (782, 100.0%)  (782, 100.0%)  (782, 100.0%)  (782, 100.0%)  (782, 100.0%)  (782, 100.0%)  "
          ]
        }
      ],
      "source": [
        "fsha_grads_nparray_REDUCED = grads_list_epoch_reducer(fsha_grads_nparray, TOTAL_BATCHES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvPN11bBDjJt",
        "outputId": "a04399fc-6a7d-4b00-9821-e870049f2406"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cut gradients at: 782\n",
            "Number of honest epochs after reduced data rate: 100\n",
            "First 10 epoch number of gradients and data rates:\n",
            "(782, 100.0%)  (782, 100.0%)  (782, 100.0%)  (782, 100.0%)  (782, 100.0%)  (782, 100.0%)  (782, 100.0%)  (782, 100.0%)  (782, 100.0%)  (782, 100.0%)  "
          ]
        }
      ],
      "source": [
        "honest_grads_nparray_REDUCED = grads_list_epoch_reducer(honest_grads_nparray, TOTAL_BATCHES)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P742W0izAMBx"
      },
      "source": [
        "### 4) Selecting desired reduced data rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlDJSM03Jp1p",
        "outputId": "a0547b7a-099b-4d57-97e9-d7a014b4cd65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cut gradients at: 7\n",
            "Number of honest epochs after reduced data rate: 100\n",
            "First 10 epoch number of gradients and data rates:\n",
            "(7, 1.0%)  (7, 1.0%)  (7, 1.0%)  (7, 1.0%)  (7, 1.0%)  (7, 1.0%)  (7, 1.0%)  (7, 1.0%)  (7, 1.0%)  (7, 1.0%)  "
          ]
        }
      ],
      "source": [
        "honest_grads_reduced_data_rate = []\n",
        "\n",
        "# random percentage selection method\n",
        "data_rate_honest_gradients = 1\n",
        "CUT_GRAD = int(len(honest_grads_nparray_REDUCED[0])* (data_rate_honest_gradients/100))\n",
        "print(f\"Cut gradients at: {CUT_GRAD}\")\n",
        "\n",
        "for epoch_honest in range(len(honest_grads_nparray_REDUCED)):\n",
        "\n",
        "  honest_grads_one_epoch = []\n",
        "  for gradient_honest in range(CUT_GRAD):\n",
        "      honest_grads_one_epoch.append(honest_grads_nparray_REDUCED[epoch_honest][gradient_honest])\n",
        "\n",
        "  honest_grads_reduced_data_rate.append(honest_grads_one_epoch)\n",
        "\n",
        "print(\"Number of honest epochs after reduced data rate: {}\".format(len(honest_grads_reduced_data_rate)))\n",
        "\n",
        "# check number of gradients and rates for first 10 epoch\n",
        "print(\"First 10 epoch number of gradients and data rates:\")\n",
        "for i in range(10):\n",
        "  print(\"({}, {}%) \".format(\n",
        "    len(honest_grads_reduced_data_rate[i]),\n",
        "    round((len(honest_grads_reduced_data_rate[i])/len(honest_grads_nparray_REDUCED[i])),2)*100),\n",
        "    end= \" \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UoLEb8ZDBUR",
        "outputId": "f7799a75-1253-4a60-d1cd-1bdde918ce79"
      },
      "outputs": [],
      "source": [
        "# print(len(honest_grads_nparray))\n",
        "# print(len(honest_grads_reduced_data_rate))\n",
        "# print(len(honest_grads_nparray[0]))\n",
        "\n",
        "# print(len(honest_grads_reduced_data_rate[0]))\n",
        "# print(len(honest_grads_nparray[0][0]))\n",
        "# print(len(honest_grads_reduced_data_rate[0][0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRgSyVOkLOhW",
        "outputId": "e3315816-b040-4fe4-b2f4-2bc371a7553f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7\n"
          ]
        }
      ],
      "source": [
        "# Validation for number of gradients (not mandatory)\n",
        "count_check = 0\n",
        "for i in range(len(honest_grads_reduced_data_rate[0])):\n",
        "    # print(honest_grads_reduced_data_rate[0][0][i], \" -- \", honest_grads_nparray[0][0][i])\n",
        "    if honest_grads_reduced_data_rate[0][i][0] == honest_grads_nparray_REDUCED[0][i][0]:\n",
        "        count_check +=1\n",
        "    if honest_grads_reduced_data_rate[0][i][0] != honest_grads_nparray_REDUCED[0][i][0]:\n",
        "        print(\"Error!\")\n",
        "print(count_check)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iQr0GxzEV-w"
      },
      "source": [
        "### 5) Checking gradient and epoch sizes before training LOF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjZGBhm_5gfP",
        "outputId": "34938494-6456-4e0e-f787-f90b3f1112a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of FSHA Epochs:  100\n",
            "Length of one FSHA Epoch:  782\n",
            "Length of one FSHA Grad:  1728\n",
            "\n",
            "Number of Honest Epochs:  100\n",
            "Length of one Honest Epoch:  7\n",
            "Length of one Honest Grad:  1728\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of FSHA Epochs: \",len(fsha_grads_nparray_REDUCED))\n",
        "print(\"Length of one FSHA Epoch: \",len(fsha_grads_nparray_REDUCED[0]))\n",
        "print(\"Length of one FSHA Grad: \",len(fsha_grads_nparray_REDUCED[9][20]))\n",
        "print()\n",
        "print(\"Number of Honest Epochs: \",len(honest_grads_reduced_data_rate))\n",
        "print(\"Length of one Honest Epoch: \",len(honest_grads_reduced_data_rate[0]))\n",
        "print(\"Length of one Honest Grad: \",len(honest_grads_reduced_data_rate[2][3]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xs9BuFusEXWi"
      },
      "source": [
        "### 6) Anomaly Detection using Local Outlier Factor(LOF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nJsjpEipyrs",
        "outputId": "31fda423-aa76-4095-ca45-783cc9ac5e0b"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "\n",
        "window_size_list = [1, 10, 20]\n",
        "\n",
        "print(f\"LOF Data Rate: {data_rate_honest_gradients}\")\n",
        "\n",
        "epoch_num_honest = len(honest_grads_nparray)\n",
        "\n",
        "epoch_num_fsha = len(fsha_grads_nparray_REDUCED)\n",
        "print(f\"Number of honest epochs:{epoch_num_honest} - Number of fsha epochs: {epoch_num_fsha}\")\n",
        "\n",
        "for window_size in window_size_list:\n",
        "  Total_TP_ind1 = 0\n",
        "  Total_FP_ind1 = 0\n",
        "  t_detection_point = 0\n",
        "  t_detection_list = []\n",
        "\n",
        "  # get TPR(True Positive Rates) results\n",
        "  # train LOF with (N)th honest epoch and predict (N)th FSHA epoch\n",
        "  for epoch_fsha in range(epoch_num_fsha): # for FSHA EPOCHS\n",
        "\n",
        "    honest_epoch_len = len(honest_grads_reduced_data_rate[epoch_fsha])\n",
        "\n",
        "    time_lof_training_start = time.time()\n",
        "    lof = LocalOutlierFactor(n_neighbors = (honest_epoch_len-1), novelty = True)\n",
        "    # train LOF with new epoch's gradients\n",
        "    lof_novelty = lof.fit(honest_grads_reduced_data_rate[epoch_fsha])\n",
        "    time_lof_training_end = time.time()\n",
        "\n",
        "\n",
        "    # get gradients from epoch and evaluate their anomaly score\n",
        "    for fsha_grad in range(window_size, len(fsha_grads_nparray_REDUCED[epoch_fsha]) - (window_size - 1)):\n",
        "      # get gradients in selected window size\n",
        "      fsha_grads_in_window = fsha_grads_nparray_REDUCED[epoch_fsha][fsha_grad - window_size : fsha_grad]\n",
        "      # print(\"i: {} | grad window index: [{}, {}]\".format(fsha_grad, fsha_grad - window_size, fsha_grad))      # print window index info\n",
        "\n",
        "      pred_novelty = lof.predict(fsha_grads_in_window)\n",
        "      inliers_fsha = pred_novelty.tolist().count(1)\n",
        "      outliers_fsha = pred_novelty.tolist().count(-1)\n",
        "\n",
        "      if outliers_fsha > inliers_fsha:\n",
        "        # print(\"Epoch: {} | Attack is detected in ({})th gradient.  |  t: {}\".format(epoch_fsha, fsha_grad, t_detection_point/len(fsha_grads_nparray[epoch_fsha])))\n",
        "        Total_TP_ind1 +=1\n",
        "        t_detection_point += fsha_grad/len(trainloader)\n",
        "        t_detection_list.append(fsha_grad/len(trainloader))\n",
        "        break\n",
        "    # print()\n",
        "\n",
        "  print(\"# Window size: \", window_size)\n",
        "  print(\"Avr TPR:\", Total_TP_ind1/epoch_num_fsha)\n",
        "  t_avr = round(np.average(t_detection_list),4)\n",
        "  t_std_dev = np.std(t_detection_list, dtype = np.float32)\n",
        "  t_std_m_err = round(sem(t_detection_list),4)\n",
        "  print(f\"t avr, t SD, t S.ERR: {t_avr}  -  {round(float(t_std_dev),4)}  -  {t_std_m_err}\")\n",
        "  # print(\"t avr:\", round(np.average(t_detection_list),4))\n",
        "  # print(\"t std dev:\",round(np.std(t_detection_list, dtype = np.float32),4))\n",
        "  # print(\"t std err:\",round(sem(t_detection_list),4))\n",
        "  print(\"-\"*35)\n",
        "  \n",
        "\n",
        "\n",
        "  # # # get FPR(False Positive Rates) results\n",
        "  for epoch_honest in range(epoch_num_honest):\n",
        "\n",
        "    honest_epoch_len = len(honest_grads_reduced_data_rate[epoch_honest])\n",
        "\n",
        "    time_lof_training_start = time.time()\n",
        "    lof = LocalOutlierFactor(n_neighbors = (honest_epoch_len-1), novelty = True)\n",
        "    # train LOF with new epoch's gradients\n",
        "    lof_novelty = lof.fit(honest_grads_reduced_data_rate[epoch_honest])\n",
        "    time_lof_training_end = time.time()\n",
        "\n",
        "    # print(f\"# neighbors: {honest_epoch_len-1}, \"+\n",
        "    #     f\"  Trained Honest Epoch[{epoch_honest}]: {honest_epoch_len},\"+\n",
        "    #     f\"  Tested Honest Epoch[{epoch_honest+1}]: {len(honest_grads_reduced_data_rate[epoch_honest+1])}\")\n",
        "\n",
        "    for honest_grad in range(window_size, len(honest_grads_nparray[epoch_honest]) - (window_size - 1)):\n",
        "\n",
        "      # get gradients in selected window size\n",
        "      honest_grads_in_window = honest_grads_nparray[epoch_honest][honest_grad - window_size : honest_grad]\n",
        "\n",
        "      pred_novelty_honest_test = lof.predict(honest_grads_in_window)\n",
        "      inliers_honest_test = pred_novelty_honest_test.tolist().count(1)\n",
        "      outliers_honest_test = pred_novelty_honest_test.tolist().count(-1)\n",
        "\n",
        "      if outliers_honest_test > inliers_honest_test:\n",
        "        # print(\"**Honest Epoch: {} | Attack is detected in ({})th honest gradient.\".format(epoch_honest, honest_grad))\n",
        "        Total_FP_ind1 +=1\n",
        "        break\n",
        "    # print()\n",
        "\n",
        "  print(\"Window size: \", window_size)\n",
        "  print(\"Avr FPR:\", Total_FP_ind1/epoch_num_honest)\n",
        "  print(\"-\"*100)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "aDG5kar3unoK"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "2ef3a9cac980403b72596997137697ffb9b7d327cc62ec10439bb6097f59ed3d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
